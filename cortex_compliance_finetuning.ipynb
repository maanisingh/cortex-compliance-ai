{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Cortex Compliance AI - Fine-Tuning via HuggingFace AutoTrain API\n\nNo GPU required! HuggingFace handles the training on their servers.\n\n## Quick Start:\n1. Get a HuggingFace token with WRITE access\n2. Run all cells\n3. Wait for training to complete (~30-60 min)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 1: Install dependencies (minimal - no GPU packages needed)\n!pip install -q huggingface_hub datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Login to Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 3: Load Training Data - 217 Russian Business Document Templates\n# Includes: Contracts, Corporate Docs, Financial, HR, Legal, Tax, Industry, Specialized and more!\n\nimport json\n\n# Download training data from GitHub (217 examples from 265 templates)\n!wget -q https://raw.githubusercontent.com/maanisingh/cortex-compliance-ai/main/combined_training_data.jsonl -O training_data.jsonl\n\n# Load training data\nTRAINING_DATA = []\nwith open('training_data.jsonl', 'r') as f:\n    for line in f:\n        TRAINING_DATA.append(json.loads(line))\n\nprint(f\"Loaded {len(TRAINING_DATA)} training examples\")\nprint(f\"\\nSample categories:\")\nfor i, item in enumerate(TRAINING_DATA[:5]):\n    print(f\"  {i+1}. {item['instruction'][:60]}...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 4: Upload dataset to HuggingFace\nfrom datasets import Dataset\nfrom huggingface_hub import whoami, HfApi\n\n# Format for fine-tuning\ndef format_for_training(example):\n    return {\"text\": f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['output']}\"}\n\ndataset = Dataset.from_list(TRAINING_DATA)\ndataset = dataset.map(format_for_training)\n\n# Upload to your HuggingFace account\nhf_user = whoami()[\"name\"]\ndataset_repo = f\"{hf_user}/cortex-compliance-data\"\n\ndataset.push_to_hub(dataset_repo, private=True)\nprint(f\"‚úÖ Dataset uploaded to: https://huggingface.co/datasets/{dataset_repo}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Start AutoTrain job via API\nimport requests\nimport os\n\nhf_user = whoami()[\"name\"]\nHF_TOKEN = os.environ.get(\"HF_TOKEN\") or input(\"Enter your HuggingFace token: \")\n\n# AutoTrain API endpoint\nresponse = requests.post(\n    \"https://huggingface.co/api/autotrain/create_project\",\n    headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n    json={\n        \"username\": hf_user,\n        \"project_name\": \"cortex-compliance-ai\",\n        \"task\": \"llm-sft\",  # Supervised fine-tuning\n        \"base_model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n        \"hub_dataset\": f\"{hf_user}/cortex-compliance-data\",\n        \"text_column\": \"text\",\n        \"train_split\": \"train\",\n        \"params\": {\n            \"epochs\": 3,\n            \"lr\": 2e-4,\n            \"batch_size\": 2,\n            \"use_peft\": True,\n            \"quantization\": \"int4\",\n        }\n    }\n)\n\nif response.status_code == 200:\n    print(f\"‚úÖ Training started!\")\n    print(f\"üìä Monitor at: https://huggingface.co/{hf_user}/cortex-compliance-ai\")\nelse:\n    print(f\"‚ùå Error: {response.text}\")\n    print(\"\\nüîÑ Alternative: Go to https://huggingface.co/autotrain and create manually\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 6: Check training status\nimport time\n\nprint(\"‚è≥ Training typically takes 30-60 minutes...\")\nprint(f\"üìä Check progress at: https://huggingface.co/{hf_user}/cortex-compliance-ai\")\nprint(\"\\nThe model will automatically appear in your HuggingFace account when done.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 7: Test the model (run after training completes)\n# You can test via the HuggingFace Inference API\n\nimport requests\n\nhf_user = whoami()[\"name\"]\nHF_TOKEN = os.environ.get(\"HF_TOKEN\") or input(\"Enter your HuggingFace token: \")\n\ntest_prompt = \"### Instruction:\\nGenerate a Personal Data Processing Policy for –û–û–û –¢–µ—Å—Ç (INN: 1234567890)\\n\\n### Response:\\n\"\n\nresponse = requests.post(\n    f\"https://api-inference.huggingface.co/models/{hf_user}/cortex-compliance-ai\",\n    headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"},\n    json={\"inputs\": test_prompt, \"parameters\": {\"max_new_tokens\": 300}}\n)\n\nif response.status_code == 200:\n    print(response.json()[0][\"generated_text\"])\nelse:\n    print(f\"Model not ready yet. Status: {response.status_code}\")\n    print(\"Wait for training to complete, then run this cell again.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Done!\n\nYour fine-tuned model will be available at: `https://huggingface.co/{your-username}/cortex-compliance-ai`\n\n**Benefits of AutoTrain API:**\n- No GPU required locally\n- HuggingFace handles all infrastructure\n- Model automatically hosted for inference\n- Use via Inference API in your Cortex GRC backend"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}